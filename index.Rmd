---
title: "A deep dive in multiple regression"
author: "Erik Bulow"
date: "2018-12-03" 
output:
  xaringan::moon_reader:
    lib_dir: libs 
    css: xaringan-themer.css
    seal: false
    yolo: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
options(htmltools.dir.version = FALSE)
library(tidyverse)

library(xaringanthemer)
mono_accent(
  base_color          = "#af151e",
  header_font_google  = google_font("Open Sans", "Extra-Bold"),
  text_font_google    = google_font("Nunito Sans", "300", "300i"),
  text_font_size      = "24px",
  header_h1_font_size = "36px",
  header_h2_font_size = "30px",
  background_image    = "index_files/figure-html/header.png",
  background_position = "top left", 
  padding             = "4em 3em 1em 3em",  
  code_font_google    = google_font("Droid Mono"),
  footnote_position_bottom = "1em",
  footnote_font_size = "16px"
)
```


background-image: url("index_files/figure-html/p1.png")
background-size: contain
---

background-image: url("https://www.hakaimagazine.com/wp-content/uploads/header-vr-coral-beauty.jpg")
background-size: cover

---

background-image: url("https://nouwcdn.com/11/1250000/1210000/1205466/pics/20161202224947217241205466_sbig.jpg")
background-size: cover

???

dykarsjuka = decompression sickness
---

# Purpose

- Aim
  - Overview to motivate further studies

--
- Does not include
  - Deep theoretical reasoning and mathematical proofs
  - Programming skills

--
- Trigger warning!
  - Mathematical formulas does occur!
  - Do not memorize them!

---

# Slides available

This presentation is available online:

**https://multreg.netlify.com**


---
```{r}
knitr::include_graphics("https://www.azquotes.com/picture-quotes/quote-all-models-are-wrong-but-some-are-useful-george-e-p-box-53-42-27.jpg")
```

---



# Modelling steps

1. Heuristic question

--
2. Formalize question

--
3. Inclusion/exclusion/missing data

--
4. Method: LM, GLM, Cox, (GGLM, GAM, ...)

--
5. *(Estimate parameters)*

--
6. Model adjustments

--
7. Validation

--
8. *(Present/describe result)*

---

# Regression

Estimate some outcome given some other characteristics.

- Linear (LM)
- Generalized linear (GLM)
  - Logistic
- Cox

---

# Definitions

- Simple/univariable

--
- Multiple/multivariable

--
- Univariate

--
- Multivariate

???

Time series analysis example of multivariate model (PROM?).

---

# The question

> How do patients with hip prosthesis feel after surgery?

--

> How do patients on average rate their over-all health one year after primary surgery?

`vas1`

---

# Method

- What sort of outcome?

--
- `vas1` is approximately continuous (0-100).

--
- Linear regression!


---

# Comparing what?

> Is there a differnece between young and old patients?

--

> Is there any association between `age` and `vas1`?

--

- Age is continues.

--
- Rarely motivated to categorize (young/old).

---

# Adjustments

- Additional variables to adjust for.

--
- DAG?

```{r}
knitr::include_graphics("https://www.researchgate.net/profile/Carlos_Del_Rio2/publication/276910016/figure/fig3/AS:271809798996000@1441815914822/Directed-acyclic-graph-DAG-illustrating-the-hypothesized-rectal-STI-HIV-association-and.png")
```
---

# Covariates

- `sex`

--
- preoperative health (`vas0`)

--
- year of birth (`byear`)

--
- Type of hospital `hosp`

--
- Thromboprophylaxis used `tromb`

--
- If hospital name has more than 10 letters (`sjname10`).

--
- Elective vs acute (`dia`)

--
- 1000 other variables that might be nice to have

???

- **Yes**, good default (compare Swedish official statistics)
- **Yes**, reasonable baseline adjustment 
- **Mayby**, could otherwise confuse age for cohort
- **Yes**, is interesting
- **Yes**, is interesting
- **No**, does not make sense.
- **No**, use for inclusion/exclusion or stratification (also no `vas0` for fractures)

---


# Collinearity

Independent variables should be independent!

--
- Avoid obvious dependencies (pairwise correlation/VIF)

--
- Can not distinguish estimates

--
- OK for prediction modelling

--
> `byear` and `age` redundant for shorter time frames. Drop `byear`!


---

# Missing data

- Exclude cases with missing $Y$
- Exclude $X_i$ with too much missing data

--
- Exclude cases with any $X_i$ missing (common but not recommended)
  - Reduce power
  - Leads to biases estimates

--
- Different sorts of (partially) missing data:
  - Missing completely at random (MCAR)
  - Missing at random (MAR)
  - Missing not at random (MNAR)

--
- Multiple imputation using chained equation (Mice, MCMC, Monte Carlo, bootstrap)

--
> Exclude `trombos` (too little data). 
 
???

- MCAR - as it sounds
- MAR - P(missing) could depend on observed variable but not on the missing value itself (more missing for patients with dementia)
- MNAR - depend on unobserved variable or on the outcome itself (too bad health to answer)

---

# Enough data?

- Too many parameters, $p$ for the data $m \Rightarrow$ overfitting

--
- Extreme case: $X =$ identity number ("saturated model")

--
- Recommendation: $p < m/ 15$ where $m$ depends on the variable:
  - continues: $n$
  - binary: $\min(n_1, n_2)$
  - ordinal: $n - \frac{1}{n^2} \sum^k_{i = 1}n^3_i$
  - survival: no of events

--
> Drop the 1000 variables that were nice to have!

---


# Notation

- We model the outcome $Y = \mathrm{vas1}$,

--
- given independent variables $X = X_1, \dots, X_4 = \mathrm{age}, \mathrm{sex}, \mathrm{vas0}, \mathrm{hosp}$,

--
- such that $Y = f(X \beta)$ for function $f(X \beta) = X \beta$ in linear regression,

--
- with coefficients $\beta = (\beta_0, \dots, \beta_4)$ estimated by $\hat \beta = \beta_0, \dots, \beta_4$

--

Note that  $$X \beta = (\beta_0, \dots, \beta_p)\cdot(1, X_1, \dots, X_p)^T = \sum_{i = 0}^p \beta_i X_i = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p$$

--

# Model

$$\mathrm{vas1} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{sex} + \beta_3 \mathrm{vas0} + \beta_4 \mathrm{hosp} $$

---

# Transformations

- `sex` as dummy variable, `sex = 1` for female.

--
- `hosp` as several dummy variables: `rural`, `county`, `university`

--
- `vas = vas1 - vas0`  

--
- Some fun with `age`: $\log(x), 1 / x, \sqrt x, x + 2x^2 - \pi x^3, \dots$, splines?

--
- `byear` (if included) categorized (ordinal?): 
  - baby-boomers
  - generation X
  - MTV-generation
  - millenials

--

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \beta_3 \mathrm{county} + \beta_4 \mathrm{university} $$

---


# Parameter estimates

Estimate $\beta = \beta_0, \dots, \beta_4$ from

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \beta_3 \mathrm{county} + \beta_4 \mathrm{university} $$
--

Black magic!

--

Result:

- $\hat \beta = \hat \beta_0, \dots, \hat \beta_4$
- CI
- p-values
- $R^2/R^2_{adj}$

---

# Model simplification/variable selection

.small[
 > "If this procedure had just been proposed as a statistical method, it would most likely be rejected because it violates every principle of statistical estimation and hypothesis testing" */ Frank E Harrell Jr.*
]

.pull-left[
## Don't!

- Overfitting
- Under-estimate CI width/p-values
- Over-estimate $R^2/R^2_{adj}$
- Ignore clinical relevance
]

.pull-right[
## Do!

- Ah, come on ... everyone does it!
- It's so easy ("just press the button!")
- No clinical theories available
- $\alpha$ not important
- External validation anyway
]

---

# If we do

- $\alpha \gg 0.05$

--
- AIC or BIC (penalized Likelihood-Ratio)

--
- Clinical judgement!

???

Keep it, even if p is relatively large.

---

# Let's do it!


$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \beta_3 \mathrm{county} + \beta_4 \mathrm{university} $$


- Test $H_0: \beta_i = 0$ for $i \in \{1, 2, 3, 4\}$

--
- Assume $p_3 = .4, p_4 = .6$ (Wald-test)

--
- Can not reject $\beta_3 = \beta_4 = 0$

--

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female}$$

???

p-values based on Wald-test for individual parameters, but LR-test for global association of full model.  
---

# Something missing?

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female}$$

```{r, out.width="75%"}
knitr::include_graphics("index_files/figure-html/graf.png")
```

---

# Residuals

- I said that $Y = X \beta$

--
- I lied! 

--
- Actually $Y = X \beta + \varepsilon$ 

--
- So what is $\varepsilon$ then?

--
- Perhaps $\varepsilon \sim N(0, \sigma)$ for some unknown $\sigma > 0$?

Is it?

--
1. Estimate $\hat \beta$

--
2. Estimate $\hat Y = X\hat \beta$

--
3. Compare estimates to observed values: $e = Y - \hat Y$

--
4. Does it look like $\varepsilon\sim N(0,\sigma)$?

---

# Example data 

```{r}
set.seed(100); library(tidyverse); library(modelr)
N <- 100

df <- 
  tibble(
    age = round(rnorm(N, 75, 10)),
    sex = factor(
            sample(c("Male", "Female"), N, TRUE, 
            c(.4, .6)), (c("Male", "Female"))
          ),
   
    # Utfall baserat på ålder och kön
    vas_mod  = 
      -10 - .2 * age + 
      3 * (sex == "Female") + 
      round(rnorm(N, 0, 3)),
  ) 

fit_mod  <- lm(vas_mod  ~ age + sex, df)
co <- round(coef(fit_mod), 1)

```

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \varepsilon,  \varepsilon \sim N(0, \sigma)$$

--
- An almighty god knows that $\beta = (\beta_0, \beta_1, \beta_2) = (-10, -0.2, 3)$ and $\sigma = 3$
  - Hence $\mathrm{vas} = -10 -0,2\cdot\mathrm{age} + 3\cdot\mathrm{female} + \varepsilon$ with $\varepsilon \sim N(0,3)$

--
- "Black magic" for humble humans estimates:
  - $\hat \beta = (\hat \beta_0, \hat \beta_1, \hat\beta_2) = (-8.7, -0.2, 2.4)$

--
- Plot $e = Y - X \hat \beta$ (in different ways)

---
# Residuals vs sex

```{r}
boxplot(resid(fit_mod) ~ df$sex)
abline(h = 0, lty = "dotted")
```

---
# Residuals vs age

```{r}
plot(df$age, resid(fit_mod))
abline(h = 0, lty = "dotted")
```

---
# Residuals vs fitted

```{r}
plot(fit_mod, 1)
```

???

# Pros and cons with residuals

* *+** Intuitive
* *-** Just for continues and non-censored variables
* *-** Subjective
* *-** Difficult if interaction exist

---

# Interpretation

- Subjective
- Confirm $\varepsilon \sim N(0, \sigma)$? Good!
- If not: 
  - Missing covariates?
  - Different functional form?
  - Interaction effects?
  - Splines?

---


# Main effects model 

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \varepsilon$$

```{r, out.width = "50%"}
knitr::include_graphics("index_files/figure-html/graf.png")
```


---

# Interaction terms 


$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \beta_3 \mathrm{age}\cdot\mathrm{female}  +\varepsilon$$

```{r}
knitr::include_graphics("https://data.library.virginia.edu/files/int11.jpeg")
```


???

Multidimensional interaction $(\beta \prod X_k)$ and functional forms (polynomial etc) also possible but hard to interpret.

---

# Interaction

- Difficult to interpret: changing $\mathrm{age}$ without $\mathrm{age}\cdot\mathrm{sex}$ impossible!

--
- Marginal effects

--
- Always include main effects!

--
- Avoid impossible combinations (pregnant men)

---

# Graphical representation

```{r}
df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth(method = "lm") +
  theme_minimal() + 
  theme(legend.position = "bottom")
```

---


# Non-parametric smoother

```{r, message=FALSE}
df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth() +
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

Some additional pattern exist (noise in this case).
---

# Flexibel parametric model

.footnote[Restricted cubic splines with 3 knots.]

```{r}
fit <- lm(vas_mod ~ age + sex + splines::ns(age, 3), df)

df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) + 
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

Is the spline a better approximation to the data (compared to the straight line)?

---

# Validation

Model validity $(R^2, R^2_{adj}, AUC, \dots)$ overestimated in case of overfitting. 

--
- External
  - On data not available during model development
  - Perhaps by different researchers

--
- Internal
  - Split-sample
  - Cross validation
  - K-fold cross validation
  - Bootstrap (jack-knife)

???

Preferred to re-do the whole analysis (variable selection) for each re-sample.

---


# Advice

## Do

- Think, study and read!
- Use clinical judgement (in variable selection, functional form, interpretation)
- Include main effects for all interactions

## Do not

- Include irrelevant variables!
- Include too many parameters compared to sample size
- Interpret coefficients of interaction effects as main effects
- Include variables that are co-linear (if interpreting is warranted)
- Extrapolate

---

background-image: url("https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/lrg/9781/4614/9781461413523.jpg")
background-size: contain
background-position: center
---

background-image: url("https://images-na.ssl-images-amazon.com/images/I/41JCfSrnrdL._SX351_BO1,204,203,200_.jpg")
background-size: contain
background-position: center
