---
title: "A deep dive in multiple regression"
author: "Erik Bülow"
date: "2018-12-03" 
output:
  xaringan::moon_reader:
    lib_dir: libs 
    css: xaringan-themer.css
    seal: false
    yolo: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
options(htmltools.dir.version = FALSE)
library(tidyverse)

library(xaringanthemer)
mono_accent(
  base_color          = "#af151e",
  header_font_google  = google_font("Open Sans", "Extra-Bold"),
  text_font_google    = google_font("Nunito Sans", "300", "300i"),
  text_font_size      = "24px",
  header_h1_font_size = "36px",
  header_h2_font_size = "30px",
  background_image    = "index_files/figure-html/header.png",
  background_position = "top left", 
  padding             = "4em 3em 1em 3em",  
  code_font_google    = google_font("Droid Mono"),
  footnote_position_bottom = "1em",
  footnote_font_size = "16px"
)
```


background-image: url("index_files/figure-html/p1.png")
background-size: contain
---

background-image: url("https://www.hakaimagazine.com/wp-content/uploads/header-vr-coral-beauty.jpg")
background-size: cover

---

background-image: url("https://nouwcdn.com/11/1250000/1210000/1205466/pics/20161202224947217241205466_sbig.jpg")
background-size: cover
---


background-image: url("https://www.forsvarsmakten.se/imagevault/publishedmedia/f21gg2n194j61dssp2sc/Inuti.jpg")
background-size: cover
---

background-image: url("https://scontent-arn2-1.xx.fbcdn.net/v/t31.0-8/22792482_1933090217012587_1033686099322050073_o.jpg?_nc_cat=111&_nc_ht=scontent-arn2-1.xx&oh=fed12504d30116056c3190e2977d93c4&oe=5C8ED1F8")
background-size: cover
---


background-image: url("index_files/figure-html/map.PNG")
background-size: cover
---

background-image: url("index_files/figure-html/satelit.PNG")
background-size: cover
---

background-image: url("index_files/figure-html/flyg.PNG")
background-size: cover
---


background-image: url("https://www.littlebigbikes.com/wp-content/uploads/2014/10/littlebig-pedal-and-crank-attachment.jpg")
background-size: cover
---


background-image: url("https://scontent-sea1-1.cdninstagram.com/vp/d287acbebbe4916df370a57c7360e0ab/5CBD9D9D/t51.2885-15/sh0.08/e35/s750x750/45268374_285962072029019_4152845941940666944_n.jpg?_nc_ht=scontent-sea1-1.cdninstagram.com&ig_cache_key=MTkxNjIxNzAyMjk4MzgyMDkzNw%3D%3D.2")
background-size: cover
---

# Purpose

- Aims
  - Introduce terminology good to know
  - Motivate further studies of the field
    
--
- Does not include
  - Deep theoretical reasoning
  - Mathematical proofs
  - Programming skills
  - Real data example

--
- Prerequisites
  - Familiarity with some mathematical notation
  - Some experience with regression analysis would help

--
- Trigger warning!
  - Mathematicical formulas does occour!
  - Do not memorize them!

---

# Modelling

> All models are wrong, some are useful. */George Box*

What is $\hat f$ such that 

$$Y = f(X) = \hat f (X) + \varepsilon \approx \hat f (X)$$

for $X = X_1, X_2, \dots, X_p$ indipendent and $Y$ dependent.

.footnote[LHS could also be for example the probability of an event (logistic regression).]

---

# Modelling steps

1. What do you want to know?

--
2. Formalize your question with regards to data.

--
3. Inclusion/exclusion criterias and missing data

--
4. Method to use: LM, GLM, Cox, GGLM, GAM, ...

--
5. Additional covariates to adjust for

--
6. *(Estimate parameters)*

--
7. Model adjustments/variable selection

--
8. Validation

--
9. *(Present/describe result)*

---

# Regression

Wants to estimate expected value (or quantile/median, probability etc) of outcome given some covariates.

- Linnear regression (LM): $f = \beta X$
- Generalized linear regression (GLM) $f = g(\beta X)$ for some function $g$
  - Logistic regression (logit-link)
- Cox $(\lambda e^{\beta X})$

We use LM as example but much is generalizable!

.footnote[$\beta X = \sum_{i = 0}^p \beta_i X_i = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p$ with $X_0 = 1$]

???

# Additional methods

Additive models
- mixed/hierarchical models
- Non-parametric regression; splines and smoothers. e.g. moving averaga or moving least squares linear regression smoother (loess)

---

# Definitions

- **Simple/univariable** = one independent variable: $X = X_1$
- **Multiple/multivariable** = multiple independent variables: $X = X_1, \dots, X_p$

Ej att förväxla med:

- **Univariate** = one dependent variable: $Y = Y_1$
- **Multivariate** = multiple dependent variables: $Y = Y_1, \dots, Y_{p'}$

???

Time series analysis example of multivariate model (PROM?).

---

# What do you want to know

Think before you ask!

> How do patients with hip prosthesis feel after surgery?

Can this be answered by SHAR? Well, if we reformulate/proximize:

> How do patients on average rate their over-all health one year after primary surgery?

Can be answered by EQ-VAS from PROM questionaire (`vas1`).

---

# Method

What sort of variable is the outcome measure?

Approximatively continous (0-100).

Hence, linear regression!

.footnote[Ordinal scale from 2017]

---

# Exposure/treatment

Should different groups of patients be compared?

(If not, regression might not be needed.)

> Is there a differnece between young and old patients?

Can this be answered?

Well, we could use age at surgery as a covariate (`age`).

> Is there any association between `age` och `vas1`?

Age is approximately continues.
Sometimes (rarely) motivated to categorize (young/old).

---

# Confounders

Additional variables to adjust for.
Think before and while you ask!

--
DAG?


```{r}
knitr::include_graphics("https://www.researchgate.net/profile/Carlos_Del_Rio2/publication/276910016/figure/fig3/AS:271809798996000@1441815914822/Directed-acyclic-graph-DAG-illustrating-the-hypothesized-rectal-STI-HIV-association-and.png")
```
---

# Independent variables

- `sex`
- preoperative health (`vas0`)
- year of birth (`byear`)
- If the first letter of hospital name is a a hard vocal (`hardvok1sjname`).
- Elektive vs acute (`dia`)

???

- **Yes**, good default (compare Swedish official statistics)
- **Yes**, reasonable baseline adjustment 
- **Mayby**, could otherwise confuse age for cohort
- **No**, could be significant but does not have any reasonable relevance (overfittnig).
- **No**, use for inclusion/exclusion or stratification (also no `vas0` for fractures)

---


# Collinearity

- Best case scenario: all independent variables orthogonal (completely different dimensions) 
- Difficult to find
- Then avoid at least obvious dependencies (pairwise correlation or VIF)
- Can not distinguish estimates and hard to make variable selections based on p-values etcetera
- OK for prediction modelling
- Autokorrelation present for modelling longer PROM-series (1, 6 and 10 years). 

> `byear` and `age` redundant for shorter time frames. Drop `byear`!

---

# Missing data

- Exclude all cases with missing response data (response analysis).

--
- Exlude cases with independent variables missing (common but not recommended)
  - Reduce power
  - Leads to biases estimates

--
- Differnt sorts of (partially) missing data:

--
  - Missing completely at random (MCAR)

--
  - Missing at random (MAR)

--
  - Missing not at random (MNAR)

--
- Multiple imputation using chained equation (Mice, MCMC, Monte Carlo, bootstrap)

???

- MCAR - as it sounds
- MAR - P(missing) could depend on observed variable but not on the missing value itself (more missing for patients with dementia)
- MNAR - depend on unobserved variable or on the outcome itself (too bad health to answer)

---

# Transformations/different functional forms

- `sex` as indicator variable, `sex = 1` for male.
- Some fun with `vas0` (`vas1`): $\log(x), 1 / x, \sqrt x, x + 2x^2 - \pi x^3, \dots$?
- `byear` (if included) might be categorized (if that would makes sence) as: baby-boomers, genarion X, MTV-generation, millenials etc. Ordinal scale (think!)?

---

# Parameter estimates

Search for $\beta = \beta_1, \dots, \beta_5$ from

$$\mathrm{vas1} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} +\beta_3 \mathrm{vas0} + \beta_4 \mathrm{byear} + \beta_5 \mathrm{hardvok1sjname} + \varepsilon$$
We do this by black magic! (linear least squares, non-linear least squares, maximum likelihood).

Result in $\hat \beta = \hat \beta_0, \dots, \hat \beta_5$ (+ CI, p-values, $R^2$ etc).

---

# Model simplification/variable selection

.small[
 > "If this procedure had just been proposed as a statistical method, it would most likely be rejected because it violates every principle of statistical estimation and hypothesis testing" */ Frank E Harrell Jr.*
]

.pull-left[
## Don't!

- Overfitting
- Reduce degrees of freedom (spend $\alpha$)
- Under estimate CI width/p-values
- Over estimate $R^2$
- Ignore clinical relevance
]

.pull-right[
## Do!

- Ah, come on ... everyone does it!
- It's so easy ("just press the button!")
- No clinical theories available
- $\alpha$ not important
- External validation anyway
- "All models are wrong, some are useful"
]

---

# If we do it

- Use $\alpha \gg 0.05$ (be conservative before you drop a variable).
- Use AIC or BIC (simpler models) based on relevance (not necessarly software defaults)
- (Compensate with degrees of freedom from full model)
- Combine with clinical judgement!
- Forward selection better than "univariable screening"

---

# Variable selection: Exemple

- Tanken är att exkludera variabler med $\beta \approx 0$ (för vilka $H_0: \beta_i = 0$ ej förkastas).
- Anta att $\beta_4 = \beta_5 \approx 0$ (med $p < 0,2$). 

$$\mathrm{vas1} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} +\beta_3 \mathrm{vas0} + \varepsilon$$

Låt `vas = vas0 - vas1`:


$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \varepsilon$$
---

# Overfitting

- För lite data $(m)$ i förhållande till antal parametrar $(p)$.

--
- Extremfall: $X =$ personnummer ("saturated modell")

--
- Allmän rekommendation: $p < m/ 15$ där m beror på variabel:
  - kontinuerlig: $n$
  - binär: $\min(n_1, n_2)$
  - ordinal: $n - \frac{1}{n^2} \sum^k_{i = 1}n^3_i$
  - överlevnad: antal händelser

--
- Shrinkage
  - Trycker ner $|\beta|$ mot 0.
  - Ridge Regression
  - Penalized maximum likelihood

---

background-image: url("index_files/figure-html/graf.png")
background-size: contain

# Något problem med den här bilden?

--
Saknar spridningsmått! Hur väl stämmer modellen?

---

# Undersök residualer

1. Skatta $\beta$ med $\hat \beta$
2. estimera $Y$ som $\hat Y = X\hat \beta$
3. Jämför estimerade och observerade värden: $e = Y - X\hat \beta$
4. Boxplot av $e$ vs `sex`.
4. Plotta $e$ vs `age`.
5. Finns någon systematik?

.footnote[Vi antar här att vi använt minsta kvadratmetoden för parameterskattning.]

---

# Låtsasdata

```{r}
set.seed(100); library(tidyverse); library(modelr)
N <- 100

df <- 
  tibble(
    age = round(rnorm(N, 75, 10)),
    sex = factor(
            sample(c("Male", "Female"), N, TRUE, 
            c(.4, .6)), (c("Male", "Female"))
          ),
   
    # Utfall baserat på ålder och kön
    vas_mod  = 
      -10 - .2 * age + 
      3 * (sex == "Female") + 
      round(rnorm(N, 0, 3)),
  ) 

fit_mod  <- lm(vas_mod  ~ age + sex, df)
co <- round(coef(fit_mod), 1)

```

$$\mathrm{vas} = -10 -0,2\cdot\mathrm{age} + 3\cdot\mathrm{female} + \varepsilon$$ 
där $\varepsilon \sim N(0,2)$

Parametrar: $\beta = (\beta_0, \beta_1, \beta_2) = (-10, -0.2, 3)$

Parameterskattning: $\hat \beta = (\hat \beta_0, \hat \beta_1, \hat\beta_2) = (-8.7, -0.2, 2.4)$

---
# Residualer vs sex

```{r}
boxplot(resid(fit_mod) ~ df$sex)
abline(h = 0, lty = "dotted")
```

---
# Residualer vs age

```{r}
plot(df$age, resid(fit_mod))
abline(h = 0, lty = "dotted")
```

---
# Residualer vs fitted

```{r}
plot(fit_mod, 1)
```

---

# Normalfördelning?

.footnote[Behövs vid interferens (konfidensintervall och p-värdestest).]

```{r}
plot(fit_mod, 2)
```

???

# För- och nackdelar med residular

**+** Intuitivt

**-** Endast för kontinuerliga icke-censurerat utfall

**-** Kräver subjektiv bedömning

**-** Svårt upptäcka interaktion

**-** Svårtolkat om interaktion finns

---

# Grafisk representation

```{r}
df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth(method = "lm") +
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

# För- och nackdelar med grafiska representationen

**+** intuitivt

**+** möjligt att se interaktioner

**-** Endast för kontinuerliga icke-censurerat utfall

**-** svårt se svagare mönser eller om man har mycket data

**-** Begränsat antal dimensioner:

- x-axel
- färg
- fyllning
- figur
- storlek
- genomskinlighet 
- linjetyp

---

# Icke-parametrisk smoother

```{r, message=FALSE}
df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth() +
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

Ser att det kan finnas annat mönster än vad som har fångats i modellen (i detta fall brus).

---

# Flexibel parametrisk modell

.footnote[Kubiska splines med 3 "knutar"]

```{r}
fit <- lm(vas_mod ~ age + sex + splines::ns(age, 3), df)

df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) + 
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

Vi kan se om en modell med splines skulle ge bättre resultat (ligga närmare smoothern)?

---


# Interaktion 

Endast huvudeffekterer (main effects): 
$$f(X) = \sum X_i \beta_i$$

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \varepsilon$$

Huvudeffekter + interaktionseffekter: 
$$f(X) = \sum X_i \beta_i + \sum \sum X_i X_j \beta_{ij}$$


$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \beta_3 \mathrm{age}\cdot\mathrm{female}  +\varepsilon$$

Interaktioner mellan fler variabler $(\beta \prod X_k)$ samt transformationer av dessa (t ex polynom) är teoretiskt möjligt men blir svårtolkat.

---

# Tolkning av interaktionseffekter

- Svårt
- Marginaleffekter
- Inkludera alltid main effects för korresponderande interaktionseffekter
- Hur hanteras omöjliga kombinationer (t ex gravida män, cementerad cup för halvprotes eller slutenvård på vårdcentral)?

---

# Validering

$R^2, R^2_{adj}, AUC, \dots$ överskattas vid overfittnig. 

--
- Extern
  - Data ej tillgänglig vid modellutvecklingen
  - Ev av andra forskare
  
--

- Intern
  - "Split-sample"
  - Korsvalidernig
  - "K-fold" korsvalidernig
  - Bootstrap (jack-knife)

???

Upprepa helst även eventuell variabelselektion i varje Bootstrap-iteration.

---



# Undvik

- Inklusion av icke motiverade variabler
- För många variabler i förhållande till observationer
- Interaktionseffekter utan main effects
- Overfitting
- Korrelerade oberoende variabler (om syftet är att förstå/skatta effekter)
- Extrapolation

---

background-image: url("https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/lrg/9781/4614/9781461413523.jpg")
background-size: contain
background-position: center
---

background-image: url("https://images-na.ssl-images-amazon.com/images/I/41JCfSrnrdL._SX351_BO1,204,203,200_.jpg")
background-size: contain
background-position: center
---
