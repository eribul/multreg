---
title: "A deep dive in multiple regression"
author: "Erik Bülow"
date: "2018-12-03" 
output:
  xaringan::moon_reader:
    lib_dir: libs 
    css: xaringan-themer.css
    seal: false
    yolo: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
options(htmltools.dir.version = FALSE)
library(tidyverse)

library(xaringanthemer)
mono_accent(
  base_color          = "#af151e",
  header_font_google  = google_font("Open Sans", "Extra-Bold"),
  text_font_google    = google_font("Nunito Sans", "300", "300i"),
  text_font_size      = "24px",
  header_h1_font_size = "36px",
  header_h2_font_size = "30px",
  background_image    = "index_files/figure-html/header.png",
  background_position = "top left", 
  padding             = "4em 3em 1em 3em",  
  code_font_google    = google_font("Droid Mono"),
  footnote_position_bottom = "1em",
  footnote_font_size = "16px"
)
```


background-image: url("index_files/figure-html/p1.png")
background-size: contain
---

background-image: url("https://www.hakaimagazine.com/wp-content/uploads/header-vr-coral-beauty.jpg")
background-size: cover

---

background-image: url("https://nouwcdn.com/11/1250000/1210000/1205466/pics/20161202224947217241205466_sbig.jpg")
background-size: cover
---

# Purpose

- Aims
  - Introduce terminology
  - Motivate further studies
  
--
- Does not include
  - Deep theoretical reasoning
  - Mathematical proofs
  - Programming skills
  - Real data example

--
- Prerequisites
  - Some experience with regression,
  - and mathematical notation

--
- Trigger warning!
  - Mathematical formulas does occur!
  - Do not memorize them!

---

# Slides available

This presentation is available online:

**https://multreg.netlify.com**

---

# Modelling

> All models are wrong, some are useful. */George Box*

--

Assume we want to model an outcome $Y$ ...

--
based on $p$ independent variables $X = X_1, X_2, \dots, X_p$,

--
such that $Y = f(X)$ for some function $f$

--
estimated by $\hat f$, such that 

$$Y = f(X) = \hat f (X) + \varepsilon \approx \hat f(X)$$

for $\varepsilon \sim N(0, \sigma^2)$ for some $\sigma > 0$.

--
This usually involves coefficients $\beta = (\beta_0, \dots, \beta_{p+1})$, such that 

--
$f (X) = f (X\beta)$ 

--
where $\beta X = \sum_{i = 0}^p \beta_i X_i = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p$ 
with $X_0 = 1$


.footnote[LHS could also be for example the probability of an event (logistic regression).]

---

# Modelling steps

1. What do you want to know?

--
2. Formalize your question with regards to data.

--
3. Inclusion/exclusion criteria and missing data

--
4. Method to use: LM, GLM, Cox, (GGLM, GAM, ...)

--
5. Additional covariates to adjust for?

--
6. *(Estimate parameters)*

--
7. Model adjustments/variable selection

--
8. Validation

--
9. *(Present/describe result)*

---

# Regression

Wants to estimate expected value (or quantile/median, probability etc) of outcome given some covariates.

- Linear regression (LM): $f = \beta X$
- Generalized linear regression (GLM) $f = g(\beta X)$ for some function $g$
  - Logistic regression (logit-link)
- Cox $(\lambda e^{\beta X})$

We use LM as example but much is generalizable!


???

# Additional methods

Additive models
- mixed/hierarchical models
- Non-parametric regression; splines and smoothers. e.g. moving average or moving least squares linear regression smoother (loess)

---

# Definitions

- **Simple/univariable** = one independent variable: $X = X_1$
- **Multiple/multivariable** = multiple independent variables: $X = X_1, \dots, X_p$

Not the same as:

- **Univariate** = one dependent variable: $Y = Y_1$
- **Multivariate** = multiple dependent variables: $Y = Y_1, \dots, Y_{p'}$

???

Time series analysis example of multivariate model (PROM?).

---

# What do you want to know

> How do patients with hip prosthesis feel after surgery?

Can this be answered by SHAR? Well, if we reformulate/approximate:

--
> How do patients on average rate their over-all health one year after primary surgery?

Can be answered by EQ-VAS from PROM questionnaire (`vas1`).

---

# Method

What sort of variable is the outcome measure?

Approximately continuous (0-100).

Hence, linear regression!

.footnote[Ordinal scale from 2017]

---

# Exposure/treatment

> Is there a differnece between young and old patients?

Can this be answered?

--

> Is there any association between `age` och `vas1`?

Age is approximately continues.

Sometimes (rarely) motivated to categorize (young/old).

---

# Confounders

Additional variables to adjust for.

Modelled similar as treatment variable.

--

DAG?


```{r}
knitr::include_graphics("https://www.researchgate.net/profile/Carlos_Del_Rio2/publication/276910016/figure/fig3/AS:271809798996000@1441815914822/Directed-acyclic-graph-DAG-illustrating-the-hypothesized-rectal-STI-HIV-association-and.png")
```
---

# Independent variables

- `sex`
- preoperative health (`vas0`)
- year of birth (`byear`)
- If the first letter of hospital name is a a hard vocal (`hardvok1sjname`).
- Elective vs acute (`dia`)

???

- **Yes**, good default (compare Swedish official statistics)
- **Yes**, reasonable baseline adjustment 
- **Mayby**, could otherwise confuse age for cohort
- **No**, could be significant but does not have any reasonable relevance (overfittnig).
- **No**, use for inclusion/exclusion or stratification (also no `vas0` for fractures)

---


# Collinearity

- Best case: independent variables orthogonal 
- Rare
- Avoid at least obvious dependencies (pairwise correlation or VIF)
- Can not distinguish estimates
- Hard to make variable selections based on p-values etc
- OK for prediction modelling
- Autocorrelation for time series (PROM at 0, 1, 6 and 10 years). 

--

> `byear` and `age` redundant for shorter time frames. Drop `byear`!

---

# Missing data

- Exclude all cases with missing response data (response analysis).

--
- Exclude cases with independent variables missing (common but not recommended)
  - Reduce power
  - Leads to biases estimates

--
- Different sorts of (partially) missing data:

--
  - Missing completely at random (MCAR)

--
  - Missing at random (MAR)

--
  - Missing not at random (MNAR)

--
- Multiple imputation using chained equation (Mice, MCMC, Monte Carlo, bootstrap)

???

- MCAR - as it sounds
- MAR - P(missing) could depend on observed variable but not on the missing value itself (more missing for patients with dementia)
- MNAR - depend on unobserved variable or on the outcome itself (too bad health to answer)

---

# Transformations/different functional forms

- `sex` as indicator variable, `sex = 1` for male.
- Some fun with `vas0` (`vas1`): $\log(x), 1 / x, \sqrt x, x + 2x^2 - \pi x^3, \dots$?
- `byear` (if included) might be categorized (if that would makes sense) as: baby-boomers, generation X, MTV-generation, millenials etc. Ordinal scale (motivate!)?

---

# Parameter estimates

Search for $\beta = \beta_1, \dots, \beta_5$ from

$$\mathrm{vas1} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} +\beta_3 \mathrm{vas0} + \beta_4 \mathrm{byear} + \beta_5 \mathrm{hardvok1sjname} + \varepsilon$$
We do this by "black magic"! (linear least squares, non-linear least squares, maximum likelihood, ...).

Result in $\hat \beta = \hat \beta_0, \dots, \hat \beta_5$ (+ CI, p-values, $R^2$ etc).

---

# Model simplification/variable selection

.small[
 > "If this procedure had just been proposed as a statistical method, it would most likely be rejected because it violates every principle of statistical estimation and hypothesis testing" */ Frank E Harrell Jr.*
]

.pull-left[
## Don't!

- Overfitting
- Reduce degrees of freedom (spend $\alpha$)
- Under-estimate CI width/p-values
- Over-estimate $R^2$
- Ignore clinical relevance
]

.pull-right[
## Do!

- Ah, come on ... everyone does it!
- It's so easy ("just press the button!")
- No clinical theories available
- $\alpha$ not important
- External validation anyway
]

---

# If we do it

- Use $\alpha \gg 0.05$ (be conservative before you drop a variable).
- Use AIC or BIC (simpler models) based on relevance (not necessary software defaults)
- (Compensate with degrees of freedom from full model)
- Combine with clinical judgement!
- Forward selection better than "univariable screening"

---

# Variable selection: Example

- Exclude variables with $\beta \approx 0$ (for which $H_0: \beta_i = 0$ not rejected).
- Assume that $\beta_4 = \beta_5 \approx 0$ (reject $H_0$ with $p = (.4, .6)$ let's say). 

$$\mathrm{vas1} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} +\beta_3 \mathrm{vas0} + \varepsilon$$

Then let: `vas = vas0 - vas1`:


$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \varepsilon$$
---

# Overfitting

- Too little data $(m)$ compared to number of parameters $(p)$.

--
- Extreme case: $X =$ identity number ("saturated model")

--
- Recommendation: $p < m/ 15$ where $m$ depends on the variable:
  - continues: $n$
  - binary: $\min(n_1, n_2)$
  - ordinal: $n - \frac{1}{n^2} \sum^k_{i = 1}n^3_i$
  - survival: no of events

--
- Shrinkage
  - Suppress $|\beta|$ towards 0.
  - Ridge Regression
  - Penalized maximum likelihood

---

background-image: url("index_files/figure-html/graf.png")
background-size: contain

# Something missing?

--
Model uncertainty!
---

# Residuals

1. Estimate $\beta$ as $\hat \beta$
2. Estimate $Y$ as $\hat Y = X\hat \beta$
3. Compare estimates to observed values: $e = Y - X\hat \beta$
4. Box-plot of $e$ vs `sex` (categorical variable).
4. Scatter-plot $e$ vs `age` (continuous variable).
5. Is there any systematic patterns?

---

# Example data 

```{r}
set.seed(100); library(tidyverse); library(modelr)
N <- 100

df <- 
  tibble(
    age = round(rnorm(N, 75, 10)),
    sex = factor(
            sample(c("Male", "Female"), N, TRUE, 
            c(.4, .6)), (c("Male", "Female"))
          ),
   
    # Utfall baserat på ålder och kön
    vas_mod  = 
      -10 - .2 * age + 
      3 * (sex == "Female") + 
      round(rnorm(N, 0, 3)),
  ) 

fit_mod  <- lm(vas_mod  ~ age + sex, df)
co <- round(coef(fit_mod), 1)

```

$$\mathrm{vas} = -10 -0,2\cdot\mathrm{age} + 3\cdot\mathrm{female} + \varepsilon$$ 
where $\varepsilon \sim N(0,2)$

Parameters: $\beta = (\beta_0, \beta_1, \beta_2) = (-10, -0.2, 3)$

Parameter estimates: $\hat \beta = (\hat \beta_0, \hat \beta_1, \hat\beta_2) = (-8.7, -0.2, 2.4)$

---
# Residuals vs sex

```{r}
boxplot(resid(fit_mod) ~ df$sex)
abline(h = 0, lty = "dotted")
```

---
# Residuals vs age

```{r}
plot(df$age, resid(fit_mod))
abline(h = 0, lty = "dotted")
```

---
# Residuals vs fitted

```{r}
plot(fit_mod, 1)
```

---

# Normality assumption

.footnote[Not always necessary but needed for some inference such as CI ans p-values.]

```{r}
plot(fit_mod, 2)
```

???

# Pros and cons with residuals

* *+** Intuitive
* *-** Just for continues and non-censored variables
* *-** Subjective
* *-** Difficult if interaction exist

---

# Graphical representation

```{r}
df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth(method = "lm") +
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

# För- och nackdelar med grafiska representationen

* *+** intuitive
* *+** possible to see interactions
* *-** Only continues non-censored variables
* *-** Difficult with weak patterns and a lot of data
* *-** Limited number of dimensions

- x-axis
- line color
- fill color
- patterns/figure points
- size
- transparency 
- line type
- time (visualization)

---

# Non-parametric smoother

```{r, message=FALSE}
df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth() +
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

Some additional pattern exist (noise in this case).
---

# Flexibel parametric model

.footnote[Restricted cubic splines with 3 knots.]

```{r}
fit <- lm(vas_mod ~ age + sex + splines::ns(age, 3), df)

df %>% 
  ggplot(aes(age, vas_mod, color = sex)) + 
  geom_point(size = 3) + 
  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) + 
  theme_minimal() + 
  theme(legend.position = "bottom")
```

???

Is the spline a better approximation to the data (compared to the straight line)?
---


# Interaction 

Main effects: 
$$f(X) = \sum X_i \beta_i$$

$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \varepsilon$$

Main effects and interaction terms: 
$$f(X) = \sum X_i \beta_i + \sum \sum X_i X_j \beta_{ij}$$


$$\mathrm{vas} = \beta_0 + \beta_1 \mathrm{age} + \beta_2\mathrm{female} + \beta_3 \mathrm{age}\cdot\mathrm{female}  +\varepsilon$$

Multidimensional interaction $(\beta \prod X_k)$ and functional forms (polynomial etc) also possible but hard to interpret.

---

# Interpretation of interaction effects

- Difficult (the effect of a change in variable $x$ holding all other variables constant is not possible)
- Marginal effects instead
- Always include main effects for corresponding interaction effects
- Impossible combinations might occur (pregnant men, cemented cup for hemiarthroplasty or in-patient primary care)?

---

# Validation

$R^2, R^2_{adj}, AUC, \dots$ overestimated in case of overfitting. 

--
- External
  - On data not available by the time of model development
  - Perhaps by different researchers
  
--

- Internal
  - Split-sample
  - Cross validation
  - K-fold cross validation
  - Bootstrap (jack-knife)

???

Preferred to re-do the whole analysis (variable selection) for each re-sample.

---



# Avoid

- Inclusion of non-clinically relevant variables
- Too many parameters compared to sample size
- Interaction effects without main effects
- Interpretation of coefficients in interaction models as if no interaction exist
- Overfitting
- Co-linearity between independent variables (if interpreting is warranted)
- Extrapolation

---

background-image: url("https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/lrg/9781/4614/9781461413523.jpg")
background-size: contain
background-position: center
---

background-image: url("https://images-na.ssl-images-amazon.com/images/I/41JCfSrnrdL._SX351_BO1,204,203,200_.jpg")
background-size: contain
background-position: center
---

background-image: url("index_files/figure-html/map.PNG")
background-size: cover
---

background-image: url("index_files/figure-html/satelit.PNG")
background-size: cover
---

background-image: url("index_files/figure-html/flyg.PNG")
background-size: cover
---

background-image: url("https://www.littlebigbikes.com/wp-content/uploads/2014/10/littlebig-pedal-and-crank-attachment.jpg")
background-size: cover
---

background-image: url("https://scontent-sea1-1.cdninstagram.com/vp/d287acbebbe4916df370a57c7360e0ab/5CBD9D9D/t51.2885-15/sh0.08/e35/s750x750/45268374_285962072029019_4152845941940666944_n.jpg?_nc_ht=scontent-sea1-1.cdninstagram.com&ig_cache_key=MTkxNjIxNzAyMjk4MzgyMDkzNw%3D%3D.2")
background-size: cover
---

background-image: url("https://scontent-arn2-1.xx.fbcdn.net/v/t31.0-8/22792482_1933090217012587_1033686099322050073_o.jpg?_nc_cat=111&_nc_ht=scontent-arn2-1.xx&oh=fed12504d30116056c3190e2977d93c4&oe=5C8ED1F8")
background-size: cover
